# 0.8.2 PostgreSQL 18 Upgrade + Schema Consolidation (P0–P5)

> **Status:** Phases 0–2 and 4 implemented ✅ · Phase 3 descoped (see [0.8.2.1 review findings](./0.8.2.1.pg18-review-findings.md)) · Phase 5 verification pending.
>
> Upgrade from PostgreSQL 17 to 18 and adopt five high-value features that eliminate app-layer work, tighten RLS security, and improve index efficiency.
> Pre-requisites: MT-2 RLS deployed (0.8 + 0.8.1 ✅).
> Project context: greenfield with no production data; prioritize correct baseline schema over backward-compatible rollout steps.
> Follows the [code review checklist](../../instructions/backend/code-review-checklist.md).

## Applicable Instruction Files

Standard backend files per the [routing table](../../instructions.md#backend-tasks).

## Problem Statement

The codebase carries several patterns that PostgreSQL 18 can handle natively:

1. **Composite indexes missing `tenant_id` as leading column.** The init migration created ~15 composite indexes (e.g. `events(visitor_id, timestamp)`) before multi-tenancy existed. MT-1 added standalone `*_tenant_id_idx` indexes but never rebuilt the composites. Under RLS every query has `WHERE tenant_id = current_setting(...)` prepended — without `tenant_id` leading, PG does a full index scan + recheck.

2. **App-generated UUIDv4 primary keys.** 13 call sites across 7 files use `randomUUID()` (Node.js `crypto`). UUIDv4 is uniformly random, causing B-tree page splits and poor cache locality on high-write tables (`events`, `sessions`). PG 18 adds native `uuidv7()` — time-ordered UUIDs that append to the B-tree tail.

3. **App-computed derived columns.** `email_domain` on `leads` is computed in `src/lib/normalize.ts` and passed in every INSERT. PG 18 virtual generated columns compute on read, cost zero storage, and guarantee consistency.

4. ~~**Upserts can't distinguish insert from update.**~~ **DESCOPED.** PG18 `OLD`/`NEW` aliases only work in `MERGE RETURNING`, not `INSERT ON CONFLICT RETURNING`. The existing `("xmax" = 0) AS is_new` pattern is correct. See [0.8.2.1 F1](./0.8.2.1.pg18-review-findings.md).

5. **RLS GUC has no defense-in-depth.** Any code running as `app_user` can call `set_config('app.current_tenant_id', ...)` with an arbitrary tenant ID. PG 18 parameter ACLs + a `SECURITY DEFINER` setter function restrict this.

## Consolidated Open Issues From 0.8 (Closed)

The remaining unchecked items in `0.8.multi-tenancy-mt2-row-level-security.md`
were operational/post-deploy tasks. Because this project is greenfield and has no
production data to preserve, those open items are consolidated here as part of a
single baseline-shaping task:

- Complete role/RLS verification in the first PG18-ready environment. → **Phase 5**
- Verify script behavior under owner-role bypass after schema updates. → **Phase 5**
- Run query-plan checks as part of baseline completion (no separate bake-in track). → **Phase 5**
- ~~Resolve Prisma compatibility approach for PG18-specific DDL~~ → **Resolved:** `@ignore` on `emailDomain` in schema.prisma + conditional VIRTUAL/STORED DDL in migration. `id` default drift is intentionally accepted (Prisma `@default(uuid())` kept for stable Prisma create semantics) and documented in [0.8.2.1 F2](./0.8.2.1.pg18-review-findings.md).
- ~~Decide ID type baseline~~ → **Deferred:** TEXT columns kept for now; `DEFAULT uuidv7()::text` applied. TEXT→UUID migration scoped to future task.

## Workflow Principles

- **One migration file, five concerns.** All DDL changes go in a single migration (`pg18_upgrade`) so schema corrections land atomically.
- **Greenfield-first DDL is acceptable.** Destructive/index-rebuild operations are allowed; this task optimizes for a correct baseline, not backward compatibility with production data.
- **App changes follow migration.** After the migration lands, update service files to remove redundant app-side logic (UUID generation, email_domain computation).
- **0.8.3 folded into 0.8.2.** Perform the index audit/EXPLAIN validation in this task instead of a separate post-bake-in phase.
- **Test gate every phase.** `make -C backend test` must pass before proceeding to the next phase.

## Current State Analysis

### Composite indexes without `tenant_id` leading (init migration)

| Index | Table | Columns |
|-------|-------|---------|
| `visitors_last_seen_at_idx` | visitors | `(last_seen_at)` |
| `sessions_visitor_id_started_at_idx` | sessions | `(visitor_id, started_at)` |
| `sessions_visitor_id_last_event_at_idx` | sessions | `(visitor_id, last_event_at)` |
| `events_visitor_id_timestamp_idx` | events | `(visitor_id, timestamp)` |
| `events_event_type_timestamp_idx` | events | `(event_type, timestamp)` |
| `events_path_timestamp_idx` | events | `(path, timestamp)` |
| `events_session_id_timestamp_idx` | events | `(session_id, timestamp)` |
| `events_property_id_timestamp_idx` | events | `(property_id, timestamp)` |
| `events_traffic_source_timestamp_idx` | events | `(traffic_source, timestamp)` |
| `leads_last_captured_at_idx` | leads | `(last_captured_at)` |
| `lead_identities_lead_id_linked_at_idx` | lead_identities | `(lead_id, linked_at)` |
| `lead_identities_visitor_id_linked_at_idx` | lead_identities | `(visitor_id, linked_at)` |
| `form_submissions_lead_id_submitted_at_idx` | form_submissions | `(lead_id, submitted_at)` |
| `form_submissions_visitor_id_submitted_at_idx` | form_submissions | `(visitor_id, submitted_at)` |
| `form_submissions_session_id_submitted_at_idx` | form_submissions | `(session_id, submitted_at)` |
| `consent_events_lead_id_timestamp_idx` | consent_events | `(lead_id, timestamp)` |
| `ingest_rejections_property_id_occurred_at_idx` | ingest_rejections | `(property_id, occurred_at)` |
| `ingest_rejections_endpoint_occurred_at_idx` | ingest_rejections | `(endpoint, occurred_at)` |
| `daily_metric_rollups_day_idx` | daily_metric_rollups | `(day)` |
| `daily_ingest_rollups_day_idx` | daily_ingest_rollups | `(day)` |

MT-1 added standalone `*_tenant_id_idx` on each table but did **not** rebuild these composites.

### `randomUUID()` call sites (app-generated UUIDv4)

| File | Line(s) | Usage |
|------|---------|-------|
| `src/services/identity.ts` | 66, 130 | Lead identity link IDs |
| `src/services/visitors.ts` | 166, 229 | Visitor + session IDs |
| `src/services/events.ts` | 237 | Event ID |
| `src/services/leads.ts` | 96, 179 | Lead + form submission IDs |
| `src/services/consent.ts` | 95 | Consent event ID |
| `src/services/metrics/rollups.ts` | 422, 475 | Rollup IDs |
| `src/app.ts` | 114 | Bootstrap tenant seed |

### `email_domain` derivation

`src/lib/normalize.ts` exports `toEmailDomain()` — called in `leads.ts` before every INSERT. The `leads.email_domain` column is a plain `VARCHAR(255)`, not generated.

### RLS GUC (pre-implementation state)

`src/lib/db.ts` formerly used `set_config('app.current_tenant_id', $1, true)` — no validation of tenant_id. **Now resolved:** `withTenant()` calls `set_tenant_context($1::uuid)` (Phase 4 ✅).

## Proposed Solution

### Phase 0 — Rebuild composite indexes with `tenant_id` leading

Drop and recreate all init-migration composite indexes with `tenant_id` as the first column. This makes RLS-filtered queries use index-only scans instead of full scans + recheck.

```sql
-- visitors
DROP INDEX visitors_last_seen_at_idx;
CREATE INDEX visitors_tenant_id_last_seen_at_idx ON visitors(tenant_id, last_seen_at);

-- sessions
DROP INDEX sessions_visitor_id_started_at_idx;
CREATE INDEX sessions_tenant_id_visitor_id_started_at_idx ON sessions(tenant_id, visitor_id, started_at);
DROP INDEX sessions_visitor_id_last_event_at_idx;
CREATE INDEX sessions_tenant_id_visitor_id_last_event_at_idx ON sessions(tenant_id, visitor_id, last_event_at);

-- events (6 indexes)
DROP INDEX events_visitor_id_timestamp_idx;
CREATE INDEX events_tenant_id_visitor_id_timestamp_idx ON events(tenant_id, visitor_id, timestamp);
DROP INDEX events_event_type_timestamp_idx;
CREATE INDEX events_tenant_id_event_type_timestamp_idx ON events(tenant_id, event_type, timestamp);
DROP INDEX events_path_timestamp_idx;
CREATE INDEX events_tenant_id_path_timestamp_idx ON events(tenant_id, path, timestamp);
DROP INDEX events_session_id_timestamp_idx;
CREATE INDEX events_tenant_id_session_id_timestamp_idx ON events(tenant_id, session_id, timestamp);
DROP INDEX events_property_id_timestamp_idx;
CREATE INDEX events_tenant_id_property_id_timestamp_idx ON events(tenant_id, property_id, timestamp);
DROP INDEX events_traffic_source_timestamp_idx;
CREATE INDEX events_tenant_id_traffic_source_timestamp_idx ON events(tenant_id, traffic_source, timestamp);

-- leads
DROP INDEX leads_last_captured_at_idx;
CREATE INDEX leads_tenant_id_last_captured_at_idx ON leads(tenant_id, last_captured_at);

-- lead_identities
DROP INDEX lead_identities_lead_id_linked_at_idx;
CREATE INDEX lead_identities_tenant_id_lead_id_linked_at_idx ON lead_identities(tenant_id, lead_id, linked_at);
DROP INDEX lead_identities_visitor_id_linked_at_idx;
CREATE INDEX lead_identities_tenant_id_visitor_id_linked_at_idx ON lead_identities(tenant_id, visitor_id, linked_at);

-- form_submissions
DROP INDEX form_submissions_lead_id_submitted_at_idx;
CREATE INDEX form_submissions_tenant_id_lead_id_submitted_at_idx ON form_submissions(tenant_id, lead_id, submitted_at);
DROP INDEX form_submissions_visitor_id_submitted_at_idx;
CREATE INDEX form_submissions_tenant_id_visitor_id_submitted_at_idx ON form_submissions(tenant_id, visitor_id, submitted_at);
DROP INDEX form_submissions_session_id_submitted_at_idx;
CREATE INDEX form_submissions_tenant_id_session_id_submitted_at_idx ON form_submissions(tenant_id, session_id, submitted_at);

-- consent_events
DROP INDEX consent_events_lead_id_timestamp_idx;
CREATE INDEX consent_events_tenant_id_lead_id_timestamp_idx ON consent_events(tenant_id, lead_id, timestamp);

-- ingest_rejections
DROP INDEX ingest_rejections_property_id_occurred_at_idx;
CREATE INDEX ingest_rejections_tenant_id_property_id_occurred_at_idx ON ingest_rejections(tenant_id, property_id, occurred_at);
DROP INDEX ingest_rejections_endpoint_occurred_at_idx;
CREATE INDEX ingest_rejections_tenant_id_endpoint_occurred_at_idx ON ingest_rejections(tenant_id, endpoint, occurred_at);

-- rollups
DROP INDEX daily_metric_rollups_day_idx;
CREATE INDEX daily_metric_rollups_tenant_id_day_idx ON daily_metric_rollups(tenant_id, day);
DROP INDEX daily_ingest_rollups_day_idx;
CREATE INDEX daily_ingest_rollups_tenant_id_day_idx ON daily_ingest_rollups(tenant_id, day);
```

Also drop the now-redundant standalone `*_tenant_id_idx` indexes — they are a subset of the new composites.

### Phase 1 — Switch PK defaults to `uuidv7()`

Add `DEFAULT uuidv7()` (or `DEFAULT uuidv7()::text` for TEXT-typed id columns) to all entity tables:

```sql
-- UUID-typed columns (tenants, api_keys, users) — already use gen_random_uuid()
ALTER TABLE tenants    ALTER COLUMN id SET DEFAULT uuidv7();
ALTER TABLE api_keys   ALTER COLUMN id SET DEFAULT uuidv7();
ALTER TABLE users      ALTER COLUMN id SET DEFAULT uuidv7();

-- TEXT-typed columns (all other tables)
ALTER TABLE visitors              ALTER COLUMN id SET DEFAULT uuidv7()::text;
ALTER TABLE sessions              ALTER COLUMN id SET DEFAULT uuidv7()::text;
ALTER TABLE events                ALTER COLUMN id SET DEFAULT uuidv7()::text;
ALTER TABLE leads                 ALTER COLUMN id SET DEFAULT uuidv7()::text;
ALTER TABLE lead_identities       ALTER COLUMN id SET DEFAULT uuidv7()::text;
ALTER TABLE form_submissions      ALTER COLUMN id SET DEFAULT uuidv7()::text;
ALTER TABLE consent_events        ALTER COLUMN id SET DEFAULT uuidv7()::text;
ALTER TABLE ingest_rejections     ALTER COLUMN id SET DEFAULT uuidv7()::text;
ALTER TABLE daily_metric_rollups  ALTER COLUMN id SET DEFAULT uuidv7()::text;
ALTER TABLE daily_ingest_rollups  ALTER COLUMN id SET DEFAULT uuidv7()::text;
```

App-side changes: remove all `randomUUID()` from INSERT statements and let the database generate IDs via `DEFAULT`. Where the service needs the new ID, use `RETURNING id`.

For batch inserts (e.g. `identity.ts` UNNEST pattern), either omit the id column (let DB generate) or use `uuidv7()` in the SQL expression.

### Phase 2 — Virtual generated column for `email_domain`

```sql
ALTER TABLE leads DROP COLUMN email_domain;
ALTER TABLE leads ADD COLUMN email_domain VARCHAR(255)
  GENERATED ALWAYS AS (split_part(email_normalized, '@', 2)) VIRTUAL;
```

App-side changes:
- Remove `toEmailDomain()` calls from `leads.ts` INSERT/UPDATE statements.
- `toEmailDomain()` in `normalize.ts` stays exported (may be used elsewhere), but annotate as deprecated for DB-side computation.

> **Note**: `email_normalized` itself stays as a stored column — the app calls `lower(trim(email))` before INSERT. Making `email_normalized` virtual would require adding a raw `email` column and backfilling, which is more disruptive. Scope that to a future task if desired.

### Phase 3 — ~~`OLD`/`NEW` RETURNING on leads upsert~~ DESCOPED

> **Descoped.** PG18's `OLD`/`NEW` table aliases in `RETURNING` are exclusive to
> `MERGE ... RETURNING`, not `INSERT ... ON CONFLICT DO UPDATE ... RETURNING`.
> The existing `("xmax" = 0) AS is_new` pattern in `leads.ts` L106 is correct and
> well-established. Rewriting as `MERGE` carries risk for no functional gain.
> See [0.8.2.1 F1](./0.8.2.1.pg18-review-findings.md) for details.

### Phase 4 — Parameter ACL + validated setter function

```sql
-- Create a SECURITY DEFINER function that validates the tenant in the active schema
CREATE OR REPLACE FUNCTION set_tenant_context(
  tid uuid,
  tenant_schema text DEFAULT 'public'
)
RETURNS void
LANGUAGE plpgsql
SECURITY DEFINER
SET search_path = pg_catalog
AS $$
DECLARE
  target_schema text := NULLIF(BTRIM(tenant_schema), '');
  tenant_exists boolean := false;
BEGIN
  IF target_schema IS NULL THEN
    target_schema := 'public';
  END IF;
  EXECUTE format(
    'SELECT EXISTS (SELECT 1 FROM %I.tenants WHERE id = $1)',
    target_schema
  ) INTO tenant_exists USING tid;
  IF NOT tenant_exists THEN
    RAISE EXCEPTION 'unknown tenant: %', tid
      USING ERRCODE = 'invalid_parameter_value';
  END IF;
  PERFORM pg_catalog.set_config('app.current_tenant_id', tid::text, true);
END;
$$;

REVOKE ALL ON FUNCTION public.set_tenant_context(uuid, text) FROM PUBLIC;
GRANT EXECUTE ON FUNCTION public.set_tenant_context(uuid, text) TO app_user;
REVOKE ALL ON PARAMETER "app.current_tenant_id" FROM app_user;
```

App-side change in `src/lib/db.ts`:
```typescript
// Before (direct set_config):
await client.query("SELECT set_config('app.current_tenant_id', $1, true)", [tenantId]);

// After (validated setter):
await client.query("SELECT set_tenant_context($1::uuid, $2::text)", [tenantId, schema]);
```

## Functions to Change

| File | Change |
|------|--------|
| `prisma/migrations/<timestamp>_pg18_upgrade/migration.sql` | New migration: index rebuilds, DEFAULT uuidv7(), virtual column, parameter ACL, setter function |
| `prisma/schema.prisma` | Update `@@index` maps to new names, mark `emailDomain` as generated, update default annotations |
| `src/services/visitors.ts` | Remove `randomUUID()` import + usage; omit `id` from INSERTs; use `RETURNING id` |
| `src/services/events.ts` | Remove `randomUUID()` from event ID; omit from INSERT; use `RETURNING id` |
| `src/services/leads.ts` | Remove `randomUUID()` + `toEmailDomain()` from INSERT ~~; add `old.id IS NULL AS is_new` to RETURNING~~ (Phase 3 descoped) |
| `src/services/identity.ts` | Remove `randomUUID()` from link IDs; let DB generate via DEFAULT in UNNEST INSERT |
| `src/services/consent.ts` | Remove `randomUUID()` from consent event INSERT |
| `src/services/metrics/rollups.ts` | Remove `crypto.randomUUID()` from rollup INSERTs |
| `src/app.ts` | Remove `randomUUID()` from tenant seed INSERT |
| `src/lib/db.ts` | Replace `set_config(...)` with `SELECT set_tenant_context($1::uuid, $2::text)` in `withTenant()` |
| `src/lib/normalize.ts` | Deprecation comment on `toEmailDomain()` (keep export for non-DB callers) |

## Related Files

| File | Note |
|------|------|
| `prisma/migrations/20260213214500_init/migration.sql` | Original indexes that need rebuilding |
| `prisma/migrations/20260216204500_mt1_tenant_model/migration.sql` | MT-1 standalone `*_tenant_id_idx` indexes to drop |
| `src/services/metrics/materialized-view.ts` | Materialized view queries benefit from rebuilt indexes but no code change needed |
| `test/helpers/db.ts` | Test DB setup — migration must apply cleanly |
| `docker-compose.oci.yml` | PG version — ~~update image tag from 17 to 18~~ already `postgres:18-alpine` ✅ |

## Agent Do / Don't (This Task)

### Do

- Combine all DDL changes into a single migration file — PG applies them transactionally.
- Favor schema correctness over compatibility shims (greenfield baseline rules).
- Run `EXPLAIN ANALYZE` on critical queries after index rebuild to verify plan improvement (document in PR).
- Update the `prisma/schema.prisma` `@@index` directives to match the new index names.
- Remove standalone `*_tenant_id_idx` indexes after rebuilding composites with `tenant_id` leading (they're now redundant subsets).
- Run `make -C backend test` after each phase.

### Do Not

- Remove `normalizeEmail()` from `normalize.ts` — `email_normalized` is still app-computed before INSERT.
- Add `CONCURRENTLY` to index creation inside the migration transaction — `CREATE INDEX CONCURRENTLY` cannot run inside a transaction block.
- Touch the materialized view refresh logic — no PG 18 feature improves it meaningfully.

## Manual Review Checklist

Per `backend/verification.md` § "Rules not yet enforced by tooling":

- [x] All 20 composite indexes rebuilt with `tenant_id` as first column.
- [x] All standalone `*_tenant_id_idx` indexes dropped (now redundant).
- [x] All `randomUUID()` import/usage removed from service files — DB generates via `DEFAULT uuidv7()`.
- [x] `RETURNING id` added wherever the service needs the generated ID after INSERT.
- [x] `email_domain` column on `leads` is `GENERATED ALWAYS AS ... VIRTUAL` — not in any INSERT or UPDATE.
- [x] `set_tenant_context()` function is `SECURITY DEFINER` with explicit `SET search_path = pg_catalog`.
- [x] `withTenant()` calls `set_tenant_context($1::uuid, $2::text)` — not `set_config(...)` directly.
- [x] `REVOKE ALL ON PARAMETER` executed for `app.current_tenant_id` from `app_user` (conditional on PG18+).
- [x] Docker Compose updated to PostgreSQL 18 image (`postgres:18-alpine`).
- [x] Prisma workflow validated for PG18-specific manual DDL (`migrate reset`,
  `migrate status` clean; schema default drift on `id` columns intentionally accepted and documented). See [0.8.2.1 F2](./0.8.2.1.pg18-review-findings.md).
- [x] Existing tests pass without modification (UUIDv4 data in test helpers still works).

---

# Consolidated Checklist

## Completed

- [x] MT-2 Row-Level Security deployed (0.8 + 0.8.1).
- [x] All composite indexes identified — 20 indexes missing `tenant_id` leading column.
- [x] All `randomUUID()` call sites identified — 13 sites across 7 files.

## Phase 0: Rebuild Composite Indexes ✅

- [x] Create migration file `20260217133000_pg18_upgrade/migration.sql`.
- [x] Drop 20 init-migration composite indexes.
- [x] Recreate all 20 with `tenant_id` as leading column.
- [x] Drop 10 standalone `*_tenant_id_idx` indexes (now redundant subsets of new composites).
- [x] Update `prisma/schema.prisma` — change all `@@index` `map:` values to new names.
- [x] **Gate**: `make -C backend test` passes; migration applies cleanly.

## Phase 1: UUIDv7 Primary Key Defaults ✅

- [x] Add `DEFAULT uuidv7()` / `DEFAULT uuidv7()::text` to all entity table `id` columns in the migration.
- [x] Decision gate: TEXT columns kept; `DEFAULT uuidv7()::text` applied. TEXT→UUID deferred to future task.
- [x] Update Docker Compose `docker-compose.oci.yml` PostgreSQL image to 18 (`postgres:18-alpine`).
- [x] Fly.io PG version not pinned in config — no change needed.
- [x] Remove `import { randomUUID } from "node:crypto"` from `visitors.ts`, `events.ts`, `leads.ts`, `identity.ts`, `consent.ts`, `app.ts`.
- [x] Remove `randomUUID` usage from `rollups.ts` (no longer imports `node:crypto` for this).
- [x] Update all INSERT statements to omit `id` column — let DB generate via DEFAULT.
- [x] Add `RETURNING id` (or `RETURNING *`) where the service needs the generated ID post-INSERT.
- [x] Update `identity.ts` batch UNNEST insert — `id` column omitted, DB generates via DEFAULT.
- [x] **Gate**: `make -C backend test` passes.

## Phase 2: Virtual Generated Column (`email_domain`) ✅

- [x] Add to migration: `ALTER TABLE leads DROP COLUMN email_domain`.
- [x] Add to migration: conditional VIRTUAL (PG18+) / STORED (PG17) generated column via `server_version_num` check.
- [x] Update `prisma/schema.prisma` — `emailDomain` marked `@ignore` with comment: "Generated in DB: split_part(email_normalized, '@', 2)".
- [x] `toEmailDomain()` calls already absent from `leads.ts` INSERT/UPDATE (removed alongside `randomUUID`).
- [x] Add deprecation JSDoc comment to `toEmailDomain()` in `normalize.ts`.
- [x] **Gate**: `make -C backend test` passes.

## Phase 3: ~~`OLD`/`NEW` RETURNING on Leads Upsert~~ DESCOPED

> PG18 `OLD`/`NEW` aliases only work in `MERGE RETURNING`, not `INSERT ON CONFLICT RETURNING`.
> Current `("xmax" = 0) AS is_new` pattern is correct. See [0.8.2.1 F1](./0.8.2.1.pg18-review-findings.md).

- [x] ~~Update `leads.ts` upsert~~ — Descoped. Existing `("xmax" = 0) AS is_new` is correct.
- [x] ~~Update lead capture service logic~~ — N/A (descoped).
- [x] **Gate**: No code change; existing tests pass.

## Phase 4: Parameter ACL + Validated Setter ✅

- [x] Add `set_tenant_context(uuid, text)` SECURITY DEFINER function to migration (with `SET search_path = pg_catalog`).
- [x] Add `REVOKE ALL ON PARAMETER "app.current_tenant_id" FROM app_user` to migration (conditional on PG18+).
- [x] Update `withTenant()` in `src/lib/db.ts` — calls `SELECT public.set_tenant_context($1::uuid, $2::text)`.
- [x] RLS policies unchanged — still use `current_setting('app.current_tenant_id')`.
- [x] **Gate**: `make -C backend test` passes ✅; direct `set_config` denial coverage added via PG-version-gated integration test (asserts denial on PG18+, skips on older versions). See [0.8.2.1 F4](./0.8.2.1.pg18-review-findings.md).

## Phase 5: Baseline Verification (Consolidated 0.8 + 0.8.3) — PENDING

- [x] Run `EXPLAIN (ANALYZE, BUFFERS)` on hot tenant-scoped queries and record plan outcomes (all 9 0.8.3 candidates audited; decisions documented in [0.8.3](./0.8.3.pg18-index-audit.md)).
- [x] Confirm RLS/role state with SQL checks:
  `SELECT relname, relrowsecurity FROM pg_class WHERE relrowsecurity = true`.
- [ ] Verify new inserts produce UUIDv7 PKs. (Local PG17 uses compatibility shim; true UUIDv7 bit-pattern verification pending PG18 runtime.)
- [x] Verify `email_domain` is computed correctly on reads.
- [x] Verify ingest + lead flows still work end-to-end (`make -C backend test` green).
- [x] Verify rollup/retention scripts still work with owner-role bypass (`rollups:run`, `rollups:status`, `retention:purge` executed successfully).
- [x] **Gate**: `make -C backend audit && make -C backend test` pass.

## Success Criteria

- [x] `make -C backend audit` passes.
- [x] `make -C backend test` passes — all existing + new tests green.
- [x] All composite indexes have `tenant_id` as leading column — `\di` shows no init-migration index names remaining.
- [x] No `randomUUID()` calls in service layer — all IDs generated by PostgreSQL `uuidv7()`.
- [x] `email_domain` is a virtual generated column — not present in any INSERT/UPDATE statement.
- [ ] `app.current_tenant_id` cannot be set directly by `app_user` — only via `set_tenant_context()`. Coverage added; PG18 runtime verification pending.
- [x] No performance regressions — key query plans verified via EXPLAIN ANALYZE (see [0.8.3](./0.8.3.pg18-index-audit.md)).
- [ ] No remaining open items from MT-2 (`0.8`) or post-bake index audit (`0.8.3`) outside this file. Remaining: PG18 runtime checks for direct `set_config` denial and UUIDv7 bit-pattern validation.
